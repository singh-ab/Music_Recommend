# Emotion-Music-Recommendation
Recommending music based on your facial expressions using the FER 2013 dataset and Spotify API.

## Project Description
The emotion recognition model is trained on the FER 2013 dataset and can detect 7 emotions. The project works by getting a live video feed from a webcam, passing it through the model to predict the emotion. Based on the predicted emotion, the app fetches a playlist of songs from Spotify using the Spotipy wrapper and recommends the songs by displaying them on the screen.

## Features
- Real-time expression detection and song recommendations.
- Playlists fetched from Spotify using the API.
- Neumorphism UI for the website.

## Running the App
Flask:
- Run `pip install -r requirements.txt` to install all dependencies.
- In `Spotipy.py`, enter your credentials generated by your Spotify Developer account in 'auth_manager'. Note: This is only required if you want to update recommendation playlists. Also, uncomment the import statement in `camera.py`.
- Run `python app.py` and give camera permission if asked.

## Tech Stack
- Keras
- TensorFlow
- Spotipy
- Tkinter (For testing)
- Flask

## Dataset
The dataset used for this project is the famous FER2013 dataset. Models trained on this dataset can classify 7 emotions. The dataset can be found [here](https://www.kaggle.com/msambare/fer2013).

Note that the dataset is highly imbalanced, with the happy class having the maximum representation. This might be a factor resulting in okayish accuracy after training.

## Model Architecture
- The model architecture is a sequential model consisting of Conv2D, MaxPool2D, Dropout, and Dense layers:
    1. Conv2D layers throughout the model have different filter sizes from 32 to 128, all with activation 'relu'.
    2. Pooling layers have a pool size of (2,2).
    3. Dropout is set to 0.25 as anything above results in poor performance.
    4. The final Dense layer has 'softmax' activation for classifying 7 emotions.
- Used 'categorical_crossentropy' for loss with 'Adam' optimizer and 'accuracy' metric.

Note: Tried implementing various other models like VGG16, but the accuracy was far too low. This model architecture gives good enough accuracy. A bit more tinkering with hyperparameters might lead to better accuracy.

## Image Processing and Training
- The images were normalized, resized to (48,48), and converted to grayscale in batches of 64 with the help of 'ImageDataGenerator' in the Keras API.
- Training took around 13 hours locally for 75 epochs with an accuracy of ~66%.

## Current Condition
The entire project works perfectly fine. Live detection gives good frame rates due to multithreading.

## Project Components
- `Spotipy` is a module for establishing a connection to and getting tracks from Spotify using the Spotipy wrapper.
- `haarcascade` is for face detection.
- `camera.py` is the module for video streaming, frame capturing, prediction, and recommendation, which are passed to `main.py`.
- `main.py` is the main Flask application file.
- `index.html` in the 'templates' directory is the web page for the application. Basic HTML and CSS.
- `utils.py` is a utility module for video streaming of the webcam with threads to enable real-time detection.
- `train.py` is the script for image processing and training the model.
